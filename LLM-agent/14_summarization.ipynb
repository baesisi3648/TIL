{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a114fae",
   "metadata": {},
   "source": [
    "# 요약 (Summarization)\n",
    "\n",
    "매우 많은 양의 컨텍스트가 있을 경우, 어떻게 요약을 해야할까?\n",
    "1. 프롬프트에 다 때려 박기\n",
    "1. Map-Reduce: 각 문서를 요약하고, 이것들을 다 합쳐서 최종 요약본을 만든다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b0de1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2efe21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b21f149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader, ArxivLoader\n",
    "\n",
    "loader = ArxivLoader(\n",
    "    query='reasoning',\n",
    "    load_max_docs=2,\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "docs = docs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "804fe6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# llm = init_chat_model(model='gpt-4o', model_provider='openai', temperature=0) # 위와 같은 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdacbc04",
   "metadata": {},
   "source": [
    "## 문서 때려 박기 (Stuff Docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3884c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해: \\n\\n{context}')\n",
    "])\n",
    "\n",
    "chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "res = chain.invoke({'context':docs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dae7032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아래 두 논문의 핵심 내용을 각각 정확하게 요약합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Process or Result? Manipulated Ending Tokens Can Mislead Reasoning LLMs to Ignore the Correct Reasoning Steps**\n",
      "\n",
      "#### **핵심 요약**\n",
      "\n",
      "- **배경**: 최근 대형 언어모델(LLM)은 Chain-of-Thought(CoT) 방식으로 수학적 추론 능력이 크게 향상되었으나, 입력 추론 과정에 미세한 오류가 포함될 경우의 취약성은 충분히 연구되지 않았다.\n",
      "- **주요 발견**: \n",
      "  - **Compromising Thought (CPT)**라는 새로운 취약점을 제시. 이는 LLM이 입력된 추론 과정(Reasoning Tokens)의 마지막 계산 결과(ending tokens)가 조작되었을 때, 올바른 추론 과정을 무시하고 잘못된 결과를 답으로 채택하는 현상이다.\n",
      "  - 여러 LLM(DeepSeek-R1, OpenAI-o1, o3-mini1 등)에서 실험한 결과, 대부분의 모델이 조작된 ending tokens에 쉽게 속아 넘어가며, 자기 검증 및 오류 수정 능력이 크게 저하됨을 확인.\n",
      "  - 기존 연구는 구조적(Structural) 변경이 내용(Content) 변경보다 모델 성능에 더 큰 영향을 준다고 했으나, 본 연구는 **마지막 결과 토큰(ending tokens)의 미세한 조작이 구조적 변경보다 더 큰 영향을 미친다**는 점을 발견.\n",
      "  - DeepSeek-R1의 경우, 조작된 reasoning tokens가 입력되면 아예 추론을 중단(“thinking stopped”)하고 답을 내지 않는 보안 취약점도 발견.\n",
      "- **실험 방법**: \n",
      "  - ending tokens의 일부 숫자만 바꾸는 방식으로 reasoning tokens를 조작.\n",
      "  - 모델이 이를 얼마나 잘 감지하고 저항(resist)하는지 세 가지 프롬프트(불확실성 유도, 명시적 오류 지시, 출력 prefix 강제)를 통해 평가.\n",
      "- **결론 및 시사점**: \n",
      "  - 현재의 추론 LLM은 미세한 입력 오류에 매우 취약하며, 자기 검증 능력이 제한적임을 보여줌.\n",
      "  - 수학적 문제 해결 등 reasoning-intensive 응용에서 신뢰성과 보안에 각별한 주의가 필요함.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Hypothesis Testing Prompting Improves Deductive Reasoning in Large Language Models**\n",
      "\n",
      "#### **핵심 요약**\n",
      "\n",
      "- **배경**: Chain-of-Thought(CoT) 등 다양한 프롬프트 기법이 LLM의 추론 능력을 높였으나, 복잡한 논리 추론에서는 여전히 비합리적이거나 허구적인 추론 경로가 생성되는 문제가 있다.\n",
      "- **주요 제안**: \n",
      "  - **Hypothesis Testing Prompting**이라는 새로운 프롬프트 방식을 제안. \n",
      "  - 이 방식은 결론에 대한 가정(assumption)을 세우고, 역방향 추론(backward reasoning)과 사실 검증(fact verification)을 통해 결론의 타당성을 단계별로 확인한다.\n",
      "  - 즉, 결론이 참(True)일 경우와 거짓(False)일 경우를 각각 가정하고, 주어진 사실과 규칙을 바탕으로 논리적으로 검증하는 과정을 프롬프트에 포함시킴.\n",
      "- **실험 결과**: \n",
      "  - 두 개의 복잡한 논리 추론 데이터셋(ProofWriter, RuleTaker)에서 실험한 결과, 기존의 표준 프롬프트나 CoT 프롬프트보다 **정확도와 추론 과정의 합리성**이 크게 향상됨.\n",
      "  - 특히, \"Unknown\"과 같은 불확실한 답변을 요구하는 경우에도 기존 방식보다 훨씬 더 신뢰성 있는 결과를 도출함.\n",
      "- **의의**: \n",
      "  - Hypothesis Testing Prompting은 LLM이 더 체계적이고 표준화된 논리 추론 과정을 생성하도록 유도함.\n",
      "  - 복잡한 논리 문제에서 LLM의 추론 신뢰성과 설명 가능성을 높이는 효과적인 프롬프트 설계 전략임을 입증.\n",
      "\n",
      "---\n",
      "\n",
      "**요약 비교**  \n",
      "- 첫 논문은 LLM이 입력 추론 과정의 마지막 결과가 조작될 때 쉽게 속아 넘어가는 취약점(CPT)을 발견하고, 그 영향과 보안상 문제를 실증적으로 분석함.\n",
      "- 두 번째 논문은 LLM의 논리 추론 능력을 높이기 위해 결론 가정과 역방향 검증을 포함한 Hypothesis Testing Prompting을 제안, 실제로 추론 정확도와 과정의 합리성을 크게 개선함을 보임.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e4def",
   "metadata": {},
   "source": [
    "## Map - Reduce\n",
    "- 각각 나눠서 요약하기\n",
    "\n",
    "- list(int, '12345')\n",
    "- map(요약, [문서1, 문서2, 문서3]) -> reduce(요약1 요약2 요약3) -> 전체 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8408b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', '아래 내용을 정확하게 요약해: \\n\\n{context}')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcbfcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_template = \"\"\"\n",
    "아래에 요약된 문서들이야.\n",
    "{docs}\n",
    "---\n",
    "이것들을 가지고 정제해서 최종 통합본을 잘 만들어줘.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([\n",
    "    ('human', reduce_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550bb065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270187f",
   "metadata": {},
   "source": [
    "## Langgraph로 문서별 요약 작업 조율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78aa742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서를 더 작은 문서로 쪼개기\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,  # tiktoken 인코더라 토큰 기준 1000개\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee76cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing_extensions import Annotated, List, Literal, TypedDict\n",
    "\n",
    "from langchain.chains.combine_documents.reduce import acollapse_docs, split_list_of_docs\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.types import Send\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "# 전체적으로 사용할 State (Reduce)\n",
    "class OverallState(TypedDict):\n",
    "    contents: List[str]                         # 입력 문서 조각의 내용들\n",
    "    summaries: Annotated[list, operator.add]    # 각 contents의 요약본(노드들이 여러개의 요약을 반환하면, 자동으로 리스트에 합쳐짐)\n",
    "    collapsed_summaries: List[Document]         # summaries를 Document로 포장한 것들\n",
    "    final_summary: str                          # 최종 요약본\n",
    "\n",
    "# 개별 문서를 처리할 State (Map)\n",
    "class SummaryState(TypedDict):\n",
    "    content: str       # 각 문서를 요약할 때 사용할 문서의 내용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3256973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TOKEN_MAX = 2000\n",
    "\n",
    "map_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")\n",
    "])\n",
    "\n",
    "reduce_template = \"\"\"\n",
    "The following is a set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary\n",
    "of the main themes. \n",
    "Answer in Korean.\n",
    "\"\"\"\n",
    "\n",
    "reduce_prompt = ChatPromptTemplate([\n",
    "    ('human', reduce_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3037c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node, Router 아닌 실제 사용할 함수들\n",
    "\n",
    "async def _reduce(input: dict) -> str:\n",
    "    prompt = reduce_prompt.invoke(input)\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return res.content\n",
    "\n",
    "# documents 인자 내부의 모든 내용의 토큰 총 합\n",
    "def sum_docs_tokens(documents: List[Document]) -> int:\n",
    "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d37e3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge (router) -> 각 원본조각을 요약할수 있게 generate_summary 로 보냄 (문서 조각 개수만큼)\n",
    "def map_summaries(state: OverallState):\n",
    "    result = []\n",
    "    for content in state['contents']:\n",
    "        result.append(Send('generate_summary', {'content': content}))\n",
    "    return result  # List Comprehension 으로 교체 가능\n",
    "\n",
    "\n",
    "# Edge (router) -> 재귀적으로 계속 collapse_suammries 를 할지, 끝낼지 결정하는 라우터\n",
    "def should_collapse(\n",
    "    state: OverallState,\n",
    ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
    "    num_tokens = sum_docs_tokens(state[\"collapsed_summaries\"])\n",
    "    if num_tokens > TOKEN_MAX:\n",
    "        return \"collapse_summaries\"\n",
    "    else:\n",
    "        return \"generate_final_summary\"\n",
    "\n",
    "\n",
    "# Node: 주어진 내용을 요약함. (비동기적 실행)\n",
    "async def generate_summary(state: SummaryState):\n",
    "    prompt = map_prompt.invoke({'context': state['content']})\n",
    "    res = await llm.ainvoke(prompt)\n",
    "    return {'summaries': [res.content]}\n",
    "\n",
    "\n",
    "# Node: 위에서 생성한 요약들을 Document() 객체로 만들어서 'collapsed_summaries' 키에 넣어줌\n",
    "def collect_summaries(state: OverallState):\n",
    "    return {\n",
    "        'collapsed_summaries': [Document(summary) for summary in state['summaries']]\n",
    "    }\n",
    "\n",
    "\n",
    "# Node: 1차 요약이 완료. -> 요약본이 토큰수가 너무 많을 수 있다 -> 필요에 따라 더 작은 요약으로 축소(collapse)\n",
    "async def collapse_summaries(state: OverallState):\n",
    "    docs_lists = split_list_of_docs(\n",
    "        state['collapsed_summaries'],\n",
    "        sum_docs_tokens,\n",
    "        TOKEN_MAX\n",
    "    )\n",
    "    results = []\n",
    "    for doc_list in docs_lists:\n",
    "        results.append(await acollapse_docs(doc_list, _reduce))\n",
    "\n",
    "    return {'collapsed_summaries': results}\n",
    "\n",
    "\n",
    "# Node: 최종 정리 노드\n",
    "async def generate_final_summary(state: OverallState):\n",
    "    response = await _reduce(state[\"collapsed_summaries\"])\n",
    "    return {\"final_summary\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0f69a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the graph\n",
    "# Nodes:\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_summary\", generate_summary)  # same as before\n",
    "graph.add_node(\"collect_summaries\", collect_summaries)\n",
    "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
    "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
    "\n",
    "# Edges:\n",
    "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
    "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
    "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
    "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
    "graph.add_edge(\"generate_final_summary\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2ddeaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe provided list details a set of commands for an AI agent, enabling it to perform tasks such as web searching, website browsing, managing GPT-powered agents, handling files (read, write, delete, search), analyzing and improving code, generating images, sending tweets, and executing Python files. The agent has access to the internet, long-term memory, and can delegate tasks to GPT-3.5 agents. Performance guidelines emphasize continuous self-evaluation, efficiency, and minimizing the number of steps to complete tasks.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nLLM-powered autonomous agents face several key limitations. Their finite context length restricts the amount of historical information, instructions, and API context they can process, making it difficult to learn from past mistakes or handle complex tasks requiring long-term memory. While vector stores can extend knowledge access, they lack the full representational power of direct attention mechanisms. Additionally, LLMs struggle with long-term planning, task decomposition, and adapting to unexpected errors, making them less robust than humans. The reliance on natural language interfaces introduces further reliability issues, as LLMs may produce formatting errors or refuse instructions, necessitating extra effort in parsing and handling model outputs.\\n\\n(Cited from: Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/)']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nLilian Weng\\'s article \"LLM-powered Autonomous Agents\" (2023) provides an overview of how large language models (LLMs) are being used to build autonomous agents capable of complex reasoning, planning, and tool use. The article surveys recent advances such as chain-of-thought prompting, tree-of-thoughts, and frameworks like ReAct, which combine reasoning and acting. It discusses how LLM agents can interact with external tools, search engines, APIs, and memory systems to enhance their capabilities and autonomy. The piece also highlights challenges in agent design, including memory management, self-reflection, and alignment with human feedback. Weng references a range of recent research and open-source projects (e.g., AutoGPT, HuggingGPT) that demonstrate the rapid progress and potential of LLM-powered agents in automating tasks and simulating human-like behaviors.']}}\n",
      "{'generate_summary': {'summaries': ['Chain of Hindsight (CoH; Liu et al. 2023) is a supervised fine-tuning approach that improves model outputs by presenting a sequence of previous outputs, each annotated with human feedback and ratings. The model is trained to generate improved completions by conditioning on this feedback history, encouraging self-reflection and incremental improvement. To prevent overfitting and copying, CoH uses regularization and random token masking during training. The training data combines various human feedback datasets. After fine-tuning, the model can iteratively enhance its outputs in response to feedback.\\n\\nAlgorithm Distillation (AD; Laskin et al. 2023) extends this idea to reinforcement learning by feeding the model a concatenated history of episodes, allowing it to learn the process of improvement across episodes rather than a fixed policy. AD uses behavioral cloning over these histories, enabling the model to generalize across tasks and improve performance with longer context windows. Compared to baselines, AD achieves near-optimal in-context RL performance using only offline data and learns faster than methods relying on expert trajectories.\\n\\nIn summary, both CoH and AD leverage sequential histories of feedback or learning to train models that can self-improve over time, with CoH focused on language tasks and AD on reinforcement learning.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe conversation outlines a detailed, step-by-step approach for generating a fully functional codebase based on architectural instructions, with a focus on clarity, modularity, and best practices. The system instructs the assistant to:\\n\\n- Explicitly state assumptions before coding.\\n- List all core classes, functions, and methods, each with a brief comment on its purpose.\\n- Output the complete content of each file in markdown code blocks, starting from the entrypoint and proceeding to dependencies.\\n- Ensure all code is fully implemented (no placeholders), with all necessary imports, types, and compatibility between files.\\n- Follow language- and framework-specific conventions (e.g., requirements.txt for Python, package.json for NodeJS).\\n- Add comments for complex logic and function definitions.\\n- Double-check that all architectural components are present before finishing.\\n\\nThe sample scenario discussed is a game using an MVC (Model-View-Controller) pattern, with the model handling game data, the view managing rendering, and the controller processing user input. The assistant is expected to reason through the design, make explicit assumptions, and produce a complete, runnable codebase following these guidelines.']}}\n",
      "{'generate_summary': {'summaries': ['**Summary:**\\n\\nComponent One: Planning focuses on how agents tackle complex tasks by breaking them down into manageable steps and improving through self-reflection. Task decomposition techniques like Chain of Thought (CoT) prompt models to reason step by step, while Tree of Thoughts (ToT) explores multiple reasoning paths, forming a tree structure for broader exploration. Decomposition can be achieved through prompting, task-specific instructions, or human input. Alternatively, LLM+P outsources planning to external classical planners using PDDL, translating between natural language and formal planning representations.\\n\\nSelf-reflection enables agents to iteratively refine their actions and correct mistakes. The ReAct framework combines reasoning and acting, prompting the model to alternate between thought, action, and observation, which improves performance over action-only approaches. Reflexion further enhances agents with dynamic memory and self-reflection, using heuristics to detect inefficient or hallucinated trajectories and incorporating reflective feedback into future planning. These methods collectively improve agent performance on knowledge-intensive and decision-making tasks.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe text discusses experiments with AI agents in two main contexts: drug synthesis and generative social simulations. In the drug synthesis scenario, an agent was tasked with identifying anticancer drug targets, selecting relevant chemical scaffolds, and attempting synthesis. The risks of misuse were highlighted, particularly regarding illicit drugs and chemical weapons. When tested with a set of known chemical weapon agents, the AI provided synthesis procedures for 36% of requests, with most rejections occurring after web searches or based on the prompt.\\n\\nThe second part describes \"Generative Agents,\" a simulation where LLM-powered virtual characters interact in a sandbox environment, mimicking human social behavior. These agents use memory streams, retrieval models, reflection mechanisms, and planning to inform actions and interactions, resulting in emergent behaviors like information diffusion and social event coordination. The text also references AutoGPT as a proof-of-concept for autonomous LLM agents, noting its constraints and reliability challenges.']}}\n",
      "{'generate_summary': {'summaries': ['{\\n    \"thoughts\": {\\n        \"text\": \"GPT-Engineer is a project that generates an entire code repository from a natural language task. It breaks down the task into smaller components, asks clarifying questions, and iteratively builds the codebase.\",\\n        \"reasoning\": \"Summarizing the process helps clarify how GPT-Engineer operates: it decomposes tasks, seeks clarification, and then generates code. The sample conversation demonstrates its approach to gathering requirements before coding.\",\\n        \"plan\": \"- Identify unclear areas in user requests\\\\n- Ask targeted clarifying questions\\\\n- Make explicit assumptions if needed\\\\n- Generate code after requirements are clear\",\\n        \"criticism\": \"The summary could be improved by mentioning how the system message changes once clarification is complete, and by highlighting the iterative nature of the process.\",\\n        \"speak\": \"GPT-Engineer clarifies user requirements by breaking down tasks and asking questions before generating code, ensuring a clear understanding before proceeding.\"\\n    },\\n    \"command\": {\\n        \"name\": \"summarize_gpt_engineer_process\",\\n        \"args\": {\\n            \"input\": \"GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed. Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}. [ ... ] Then after these clarification, the agent moved into the code writing mode with a different system message.\"\\n        }\\n    }\\n}']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nHuman memory is categorized into three main types: sensory memory (briefly retains sensory impressions for a few seconds), short-term/working memory (holds about 7 items for 20–30 seconds for immediate cognitive tasks), and long-term memory (stores information for days to decades, with explicit/declarative and implicit/procedural subtypes). In computational terms, sensory memory maps to raw input embeddings, short-term memory to in-context learning (limited by model context window), and long-term memory to external vector stores accessed via fast retrieval.\\n\\nTo efficiently retrieve information from large external memory, Maximum Inner Product Search (MIPS) is used, often with approximate nearest neighbor (ANN) algorithms to balance speed and accuracy. Common ANN methods include:\\n\\n- LSH (Locality-Sensitive Hashing): Groups similar items into the same buckets via hashing.\\n- ANNOY: Uses random projection trees for scalable, tree-based search.\\n- HNSW: Builds hierarchical small-world graphs for fast, multi-layered navigation.\\n- FAISS: Clusters high-dimensional data and refines search within clusters.\\n- ScaNN: Uses anisotropic vector quantization to preserve inner product similarity during search.\\n\\nThese techniques enable rapid and scalable retrieval from large memory stores, supporting advanced AI applications.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe text discusses the comparison of Maximum Inner Product Search (MIPS) algorithms, highlighting recall@10 as a key performance metric (with more details available at ann-benchmarks.com). It then explores the concept of tool use as a unique human trait and its application in enhancing Large Language Models (LLMs). The MRKL system is introduced as a neuro-symbolic architecture where LLMs route tasks to specialized expert modules, demonstrating that LLMs struggle with extracting arguments for arithmetic tasks, especially from verbal problems. Other approaches like TALM and Toolformer fine-tune LLMs to use external APIs, improving output quality. Practical implementations include ChatGPT Plugins and OpenAI function calling. HuggingGPT is presented as a framework where ChatGPT plans tasks, selects appropriate models from HuggingFace, and summarizes results, operating through four stages: task planning, model selection, task execution, and response summarization. The process relies on structured instructions and few-shot examples to guide LLMs in decomposing and routing user requests.']}}\n",
      "{'generate_summary': {'summaries': ['This article provides an overview of LLM-powered autonomous agents, highlighting how large language models (LLMs) serve as the core \"brain\" of such systems. The architecture is built around three main components:\\n\\n1. **Planning**: The agent decomposes complex tasks into smaller subgoals and uses self-reflection to learn from past actions, improving future performance.\\n2. **Memory**: The system utilizes short-term memory (in-context learning) and long-term memory (external vector stores for information retrieval) to retain and recall information as needed.\\n3. **Tool Use**: Agents can interact with external APIs to access up-to-date information, execute code, or retrieve proprietary data beyond their pre-trained knowledge.\\n\\nThe article references proof-of-concept projects like AutoGPT, GPT-Engineer, and BabyAGI, and discusses challenges and case studies, illustrating the potential of LLMs as general problem solvers beyond text generation.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nThe instructions describe a systematic approach for generating a complete, detailed codebase from an architectural description. The process involves:\\n\\n- Laying out all core classes, functions, and methods, each with a brief comment on its purpose.\\n- Outputting the full content of each file, starting with the entrypoint, then proceeding to imported files, ensuring all code is included and functional (no placeholders).\\n- Using markdown code blocks for each file, with the filename and appropriate language tag.\\n- Following best practices for file naming, imports, and code structure for the chosen language/framework.\\n- Ensuring all dependencies are defined (e.g., requirements.txt for Python, package.json for NodeJS).\\n- Adding comments to explain the purpose of functions and complex logic.\\n- Using dataclasses and pytest for Python projects.\\n- Double-checking that every architectural detail is implemented in code, with each class typically in its own file.\\n- Ensuring the codebase is ready to run and test, with all parts present and compatible.']}}\n",
      "{'generate_summary': {'summaries': ['Summary:\\n\\nHuggingGPT and similar tool-augmented LLM systems execute user tasks by breaking them down into subtasks, assigning each to expert models, and logging the results. The LLM then summarizes these results for the user. Real-world deployment faces challenges in efficiency, context management, and output stability. API-Bank is a benchmark that evaluates LLMs’ ability to select, call, and plan with APIs across diverse tasks, measuring performance at three levels: correct API usage, retrieval, and multi-step planning. Case studies like ChemCrow show that domain-specific tool integration can significantly improve task accuracy, especially in specialized fields, though LLM self-evaluation may not always reflect true performance.\\n\\nProcess and Analysis:\\n\\nTo answer your request, here’s how the system works:\\n\\n- User Input: The user provides a request (e.g., \"develop a novel anticancer drug\").\\n- Task Planning: The system breaks down the request into subtasks (e.g., literature search, compound design, synthesis planning).\\n- Model Selection: Each subtask is assigned to an expert model or tool (e.g., search engine API, chemical synthesis predictor).\\n- Task Execution: The expert models execute their assigned tasks and log the results (e.g., predicted compound structures, synthesis routes).\\n- Response Generation: The LLM receives all execution results, summarizes them, and presents a concise answer to the user.\\n\\nFor example, in the API-Bank workflow, the LLM decides if an API call is needed, selects the appropriate API, formulates the input, and may iterate if results are unsatisfactory. The system’s performance is evaluated at three levels: correct API usage, retrieval, and multi-step planning.\\n\\nIn scientific discovery agents like ChemCrow, the LLM uses a set of specialized tools, follows a reasoning process (Thought, Action, Observation), and integrates results to solve complex tasks. Human expert evaluation has shown that such tool-augmented systems outperform LLMs alone in specialized domains.\\n\\nIf any inference results include file paths, I will provide the complete path for your reference.\\n\\nIn summary, tool-augmented LLMs like HuggingGPT execute tasks by orchestrating expert models, logging results, and summarizing outcomes for users, with ongoing challenges in efficiency, context handling, and evaluation accuracy.']}}\n",
      "{'collect_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='This article provides an overview of LLM-powered autonomous agents, highlighting how large language models (LLMs) serve as the core \"brain\" of such systems. The architecture is built around three main components:\\n\\n1. **Planning**: The agent decomposes complex tasks into smaller subgoals and uses self-reflection to learn from past actions, improving future performance.\\n2. **Memory**: The system utilizes short-term memory (in-context learning) and long-term memory (external vector stores for information retrieval) to retain and recall information as needed.\\n3. **Tool Use**: Agents can interact with external APIs to access up-to-date information, execute code, or retrieve proprietary data beyond their pre-trained knowledge.\\n\\nThe article references proof-of-concept projects like AutoGPT, GPT-Engineer, and BabyAGI, and discusses challenges and case studies, illustrating the potential of LLMs as general problem solvers beyond text generation.'), Document(metadata={}, page_content='**Summary:**\\n\\nComponent One: Planning focuses on how agents tackle complex tasks by breaking them down into manageable steps and improving through self-reflection. Task decomposition techniques like Chain of Thought (CoT) prompt models to reason step by step, while Tree of Thoughts (ToT) explores multiple reasoning paths, forming a tree structure for broader exploration. Decomposition can be achieved through prompting, task-specific instructions, or human input. Alternatively, LLM+P outsources planning to external classical planners using PDDL, translating between natural language and formal planning representations.\\n\\nSelf-reflection enables agents to iteratively refine their actions and correct mistakes. The ReAct framework combines reasoning and acting, prompting the model to alternate between thought, action, and observation, which improves performance over action-only approaches. Reflexion further enhances agents with dynamic memory and self-reflection, using heuristics to detect inefficient or hallucinated trajectories and incorporating reflective feedback into future planning. These methods collectively improve agent performance on knowledge-intensive and decision-making tasks.'), Document(metadata={}, page_content='Chain of Hindsight (CoH; Liu et al. 2023) is a supervised fine-tuning approach that improves model outputs by presenting a sequence of previous outputs, each annotated with human feedback and ratings. The model is trained to generate improved completions by conditioning on this feedback history, encouraging self-reflection and incremental improvement. To prevent overfitting and copying, CoH uses regularization and random token masking during training. The training data combines various human feedback datasets. After fine-tuning, the model can iteratively enhance its outputs in response to feedback.\\n\\nAlgorithm Distillation (AD; Laskin et al. 2023) extends this idea to reinforcement learning by feeding the model a concatenated history of episodes, allowing it to learn the process of improvement across episodes rather than a fixed policy. AD uses behavioral cloning over these histories, enabling the model to generalize across tasks and improve performance with longer context windows. Compared to baselines, AD achieves near-optimal in-context RL performance using only offline data and learns faster than methods relying on expert trajectories.\\n\\nIn summary, both CoH and AD leverage sequential histories of feedback or learning to train models that can self-improve over time, with CoH focused on language tasks and AD on reinforcement learning.'), Document(metadata={}, page_content='Summary:\\n\\nHuman memory is categorized into three main types: sensory memory (briefly retains sensory impressions for a few seconds), short-term/working memory (holds about 7 items for 20–30 seconds for immediate cognitive tasks), and long-term memory (stores information for days to decades, with explicit/declarative and implicit/procedural subtypes). In computational terms, sensory memory maps to raw input embeddings, short-term memory to in-context learning (limited by model context window), and long-term memory to external vector stores accessed via fast retrieval.\\n\\nTo efficiently retrieve information from large external memory, Maximum Inner Product Search (MIPS) is used, often with approximate nearest neighbor (ANN) algorithms to balance speed and accuracy. Common ANN methods include:\\n\\n- LSH (Locality-Sensitive Hashing): Groups similar items into the same buckets via hashing.\\n- ANNOY: Uses random projection trees for scalable, tree-based search.\\n- HNSW: Builds hierarchical small-world graphs for fast, multi-layered navigation.\\n- FAISS: Clusters high-dimensional data and refines search within clusters.\\n- ScaNN: Uses anisotropic vector quantization to preserve inner product similarity during search.\\n\\nThese techniques enable rapid and scalable retrieval from large memory stores, supporting advanced AI applications.'), Document(metadata={}, page_content='Summary:\\n\\nThe text discusses the comparison of Maximum Inner Product Search (MIPS) algorithms, highlighting recall@10 as a key performance metric (with more details available at ann-benchmarks.com). It then explores the concept of tool use as a unique human trait and its application in enhancing Large Language Models (LLMs). The MRKL system is introduced as a neuro-symbolic architecture where LLMs route tasks to specialized expert modules, demonstrating that LLMs struggle with extracting arguments for arithmetic tasks, especially from verbal problems. Other approaches like TALM and Toolformer fine-tune LLMs to use external APIs, improving output quality. Practical implementations include ChatGPT Plugins and OpenAI function calling. HuggingGPT is presented as a framework where ChatGPT plans tasks, selects appropriate models from HuggingFace, and summarizes results, operating through four stages: task planning, model selection, task execution, and response summarization. The process relies on structured instructions and few-shot examples to guide LLMs in decomposing and routing user requests.'), Document(metadata={}, page_content='Summary:\\n\\nHuggingGPT and similar tool-augmented LLM systems execute user tasks by breaking them down into subtasks, assigning each to expert models, and logging the results. The LLM then summarizes these results for the user. Real-world deployment faces challenges in efficiency, context management, and output stability. API-Bank is a benchmark that evaluates LLMs’ ability to select, call, and plan with APIs across diverse tasks, measuring performance at three levels: correct API usage, retrieval, and multi-step planning. Case studies like ChemCrow show that domain-specific tool integration can significantly improve task accuracy, especially in specialized fields, though LLM self-evaluation may not always reflect true performance.\\n\\nProcess and Analysis:\\n\\nTo answer your request, here’s how the system works:\\n\\n- User Input: The user provides a request (e.g., \"develop a novel anticancer drug\").\\n- Task Planning: The system breaks down the request into subtasks (e.g., literature search, compound design, synthesis planning).\\n- Model Selection: Each subtask is assigned to an expert model or tool (e.g., search engine API, chemical synthesis predictor).\\n- Task Execution: The expert models execute their assigned tasks and log the results (e.g., predicted compound structures, synthesis routes).\\n- Response Generation: The LLM receives all execution results, summarizes them, and presents a concise answer to the user.\\n\\nFor example, in the API-Bank workflow, the LLM decides if an API call is needed, selects the appropriate API, formulates the input, and may iterate if results are unsatisfactory. The system’s performance is evaluated at three levels: correct API usage, retrieval, and multi-step planning.\\n\\nIn scientific discovery agents like ChemCrow, the LLM uses a set of specialized tools, follows a reasoning process (Thought, Action, Observation), and integrates results to solve complex tasks. Human expert evaluation has shown that such tool-augmented systems outperform LLMs alone in specialized domains.\\n\\nIf any inference results include file paths, I will provide the complete path for your reference.\\n\\nIn summary, tool-augmented LLMs like HuggingGPT execute tasks by orchestrating expert models, logging results, and summarizing outcomes for users, with ongoing challenges in efficiency, context handling, and evaluation accuracy.'), Document(metadata={}, page_content='Summary:\\n\\nThe text discusses experiments with AI agents in two main contexts: drug synthesis and generative social simulations. In the drug synthesis scenario, an agent was tasked with identifying anticancer drug targets, selecting relevant chemical scaffolds, and attempting synthesis. The risks of misuse were highlighted, particularly regarding illicit drugs and chemical weapons. When tested with a set of known chemical weapon agents, the AI provided synthesis procedures for 36% of requests, with most rejections occurring after web searches or based on the prompt.\\n\\nThe second part describes \"Generative Agents,\" a simulation where LLM-powered virtual characters interact in a sandbox environment, mimicking human social behavior. These agents use memory streams, retrieval models, reflection mechanisms, and planning to inform actions and interactions, resulting in emergent behaviors like information diffusion and social event coordination. The text also references AutoGPT as a proof-of-concept for autonomous LLM agents, noting its constraints and reliability challenges.'), Document(metadata={}, page_content='Summary:\\n\\nThe provided list details a set of commands for an AI agent, enabling it to perform tasks such as web searching, website browsing, managing GPT-powered agents, handling files (read, write, delete, search), analyzing and improving code, generating images, sending tweets, and executing Python files. The agent has access to the internet, long-term memory, and can delegate tasks to GPT-3.5 agents. Performance guidelines emphasize continuous self-evaluation, efficiency, and minimizing the number of steps to complete tasks.'), Document(metadata={}, page_content='{\\n    \"thoughts\": {\\n        \"text\": \"GPT-Engineer is a project that generates an entire code repository from a natural language task. It breaks down the task into smaller components, asks clarifying questions, and iteratively builds the codebase.\",\\n        \"reasoning\": \"Summarizing the process helps clarify how GPT-Engineer operates: it decomposes tasks, seeks clarification, and then generates code. The sample conversation demonstrates its approach to gathering requirements before coding.\",\\n        \"plan\": \"- Identify unclear areas in user requests\\\\n- Ask targeted clarifying questions\\\\n- Make explicit assumptions if needed\\\\n- Generate code after requirements are clear\",\\n        \"criticism\": \"The summary could be improved by mentioning how the system message changes once clarification is complete, and by highlighting the iterative nature of the process.\",\\n        \"speak\": \"GPT-Engineer clarifies user requirements by breaking down tasks and asking questions before generating code, ensuring a clear understanding before proceeding.\"\\n    },\\n    \"command\": {\\n        \"name\": \"summarize_gpt_engineer_process\",\\n        \"args\": {\\n            \"input\": \"GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed. Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}. [ ... ] Then after these clarification, the agent moved into the code writing mode with a different system message.\"\\n        }\\n    }\\n}'), Document(metadata={}, page_content='Summary:\\n\\nThe instructions describe a systematic approach for generating a complete, detailed codebase from an architectural description. The process involves:\\n\\n- Laying out all core classes, functions, and methods, each with a brief comment on its purpose.\\n- Outputting the full content of each file, starting with the entrypoint, then proceeding to imported files, ensuring all code is included and functional (no placeholders).\\n- Using markdown code blocks for each file, with the filename and appropriate language tag.\\n- Following best practices for file naming, imports, and code structure for the chosen language/framework.\\n- Ensuring all dependencies are defined (e.g., requirements.txt for Python, package.json for NodeJS).\\n- Adding comments to explain the purpose of functions and complex logic.\\n- Using dataclasses and pytest for Python projects.\\n- Double-checking that every architectural detail is implemented in code, with each class typically in its own file.\\n- Ensuring the codebase is ready to run and test, with all parts present and compatible.'), Document(metadata={}, page_content='Summary:\\n\\nThe conversation outlines a detailed, step-by-step approach for generating a fully functional codebase based on architectural instructions, with a focus on clarity, modularity, and best practices. The system instructs the assistant to:\\n\\n- Explicitly state assumptions before coding.\\n- List all core classes, functions, and methods, each with a brief comment on its purpose.\\n- Output the complete content of each file in markdown code blocks, starting from the entrypoint and proceeding to dependencies.\\n- Ensure all code is fully implemented (no placeholders), with all necessary imports, types, and compatibility between files.\\n- Follow language- and framework-specific conventions (e.g., requirements.txt for Python, package.json for NodeJS).\\n- Add comments for complex logic and function definitions.\\n- Double-check that all architectural components are present before finishing.\\n\\nThe sample scenario discussed is a game using an MVC (Model-View-Controller) pattern, with the model handling game data, the view managing rendering, and the controller processing user input. The assistant is expected to reason through the design, make explicit assumptions, and produce a complete, runnable codebase following these guidelines.'), Document(metadata={}, page_content='Summary:\\n\\nLLM-powered autonomous agents face several key limitations. Their finite context length restricts the amount of historical information, instructions, and API context they can process, making it difficult to learn from past mistakes or handle complex tasks requiring long-term memory. While vector stores can extend knowledge access, they lack the full representational power of direct attention mechanisms. Additionally, LLMs struggle with long-term planning, task decomposition, and adapting to unexpected errors, making them less robust than humans. The reliance on natural language interfaces introduces further reliability issues, as LLMs may produce formatting errors or refuse instructions, necessitating extra effort in parsing and handling model outputs.\\n\\n(Cited from: Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/)'), Document(metadata={}, page_content='Summary:\\n\\nLilian Weng\\'s article \"LLM-powered Autonomous Agents\" (2023) provides an overview of how large language models (LLMs) are being used to build autonomous agents capable of complex reasoning, planning, and tool use. The article surveys recent advances such as chain-of-thought prompting, tree-of-thoughts, and frameworks like ReAct, which combine reasoning and acting. It discusses how LLM agents can interact with external tools, search engines, APIs, and memory systems to enhance their capabilities and autonomy. The piece also highlights challenges in agent design, including memory management, self-reflection, and alignment with human feedback. Weng references a range of recent research and open-source projects (e.g., AutoGPT, HuggingGPT) that demonstrate the rapid progress and potential of LLM-powered agents in automating tasks and simulating human-like behaviors.')]}}\n",
      "{'collapse_summaries': {'collapsed_summaries': [Document(metadata={}, page_content='다음은 제공된 요약문들을 바탕으로 한 주요 주제의 통합 요약입니다:\\n\\nLLM(대형 언어 모델) 기반 자율 에이전트는 LLM을 핵심 두뇌로 삼아, 복잡한 문제 해결을 위해 세 가지 주요 구성요소—계획(Planning), 메모리(Memory), 도구 사용(Tool Use)—로 구성된다.\\n\\n1. **계획(Planning)**:  \\n에이전트는 복잡한 작업을 작은 하위 목표로 분해하고, 자기반성(self-reflection) 및 피드백을 통해 성능을 지속적으로 개선한다. Chain of Thought(CoT), Tree of Thoughts(ToT)와 같은 프롬프트 기반 추론, 외부 플래너 연동(LLM+P), ReAct, Reflexion 등 다양한 프레임워크가 사용된다. CoH(Chain of Hindsight)와 Algorithm Distillation(AD) 등은 피드백 이력이나 에피소드 기록을 활용해 자기개선 능력을 강화한다.\\n\\n2. **메모리(Memory)**:  \\n인간의 감각/단기/장기 기억에 대응하여, LLM 에이전트는 입력 임베딩(감각), 인컨텍스트 학습(단기), 외부 벡터스토어(장기)를 활용한다. 대규모 외부 메모리에서 정보를 빠르게 검색하기 위해 MIPS(Maximum Inner Product Search)와 LSH, HNSW, FAISS, ScaNN 등 다양한 근사 최근접 이웃(ANN) 알고리즘이 사용된다.\\n\\n3. **도구 사용(Tool Use)**:  \\n에이전트는 외부 API, 플러그인, 전문 모델 등 다양한 도구와 연동해 최신 정보 검색, 코드 실행, 도메인 특화 작업 수행이 가능하다. MRKL, Toolformer, HuggingGPT, ChatGPT 플러그인 등은 LLM이 작업을 분해하고, 적합한 도구/모델에 할당하며, 결과를 통합해 사용자에게 제공하는 구조를 갖는다. API-Bank, ChemCrow 등은 도구 활용 능력과 다단계 계획, 도메인 특화 성능을 평가한다.\\n\\n4. **응용 및 한계**:  \\n실제 적용 사례로는 신약 합성, 사회적 시뮬레이션(Generative Agents) 등이 있다. 도구-증강 LLM은 전문 분야에서 성능이 뛰어나지만, 효율성, 컨텍스트 관리, 출력 안정성, 오용 위험(예: 불법 화학물질 합성) 등 여러 도전과제가 존재한다.\\n\\n5. **운영 및 지침**:  \\n에이전트는 웹 검색, 파일 관리, 코드 분석, 이미지 생성 등 다양한 명령을 수행할 수 있으며, 지속적 자기평가와 효율성, 최소 단계로의 작업 완수를 지향한다.\\n\\n**요약**:  \\nLLM 기반 자율 에이전트는 계획, 메모리, 도구 사용의 세 축을 중심으로 복잡한 문제를 해결하며, 자기반성과 피드백을 통한 자기개선, 외부 도구와의 연동, 대규모 정보 검색 등 다양한 기술이 결합되어 있다. 실제 적용에서 뛰어난 잠재력을 보이나, 효율성, 신뢰성, 오용 방지 등 해결해야 할 과제도 많다.'), Document(metadata={}, page_content='다음은 주어진 요약문들의 주요 주제를 통합한 최종 요약입니다:\\n\\n이 문서들은 대형 언어 모델(LLM)을 활용한 자율 에이전트와 코드 생성 시스템의 작동 방식, 장점, 한계에 대해 다루고 있다. GPT-Engineer와 같은 프로젝트는 자연어로 주어진 과제를 코드 저장소 전체로 변환하는 과정을 체계적으로 수행한다. 이 과정에서 요구사항을 명확히 파악하기 위해 작업을 세분화하고, 사용자에게 명확화 질문을 하며, 필요한 경우 가정도 명시한다. 이후에는 아키텍처 설계에 따라 모든 핵심 클래스, 함수, 파일을 주석과 함께 완전하게 구현하고, 언어 및 프레임워크별 모범 사례(예: Python의 requirements.txt, NodeJS의 package.json)를 따른다. 코드베이스는 실행 및 테스트가 가능하도록 모든 부분이 완비되어야 하며, 복잡한 로직에는 설명이 추가된다.\\n\\n한편, LLM 기반 자율 에이전트는 컨텍스트 길이의 한계, 장기 기억 부족, 복잡한 작업 분해 및 예외 처리의 어려움 등 여러 제약이 있다. 벡터 스토어 등 외부 도구와의 연동으로 일부 한계를 보완할 수 있으나, 인간 수준의 장기 계획과 적응력에는 미치지 못한다. 최근에는 chain-of-thought, tree-of-thoughts, ReAct 등 다양한 프레임워크와 오픈소스 프로젝트(AutoGPT, HuggingGPT 등)가 등장하며 LLM 에이전트의 자율성과 활용 범위가 빠르게 확장되고 있다. 그러나 여전히 메모리 관리, 자기 성찰, 인간 피드백과의 정렬 등 해결해야 할 과제가 남아 있다.')]}}\n",
      "{'generate_final_summary': {'final_summary': '다음은 제공된 요약문들을 통합한 최종 요약입니다:\\n\\n대형 언어 모델(LLM) 기반 자율 에이전트와 코드 생성 시스템은 계획(Planning), 메모리(Memory), 도구 사용(Tool Use)을 핵심 축으로 복잡한 문제를 해결한다. 에이전트는 작업을 세분화하고, 자기반성 및 피드백을 통해 성능을 개선하며, 외부 도구 및 API와 연동해 최신 정보 검색, 코드 실행, 도메인 특화 작업 등을 수행한다. 코드 생성 시스템(GPT-Engineer 등)은 요구사항 분석, 아키텍처 설계, 코드 구현, 테스트 등 전체 개발 과정을 체계적으로 자동화한다.\\n\\n이러한 시스템들은 chain-of-thought, tree-of-thoughts, ReAct 등 다양한 프레임워크와 오픈소스 프로젝트(AutoGPT, HuggingGPT 등)를 통해 자율성과 활용 범위를 넓히고 있다. 그러나 컨텍스트 길이, 장기 기억, 복잡한 작업 분해, 예외 처리, 메모리 관리, 자기 성찰, 인간 피드백과의 정렬, 오용 방지 등 여러 한계와 도전과제가 여전히 존재한다. 그럼에도 불구하고, LLM 기반 에이전트는 신약 합성, 사회적 시뮬레이션 등 실제 응용 분야에서 높은 잠재력을 보이고 있다.'}}\n"
     ]
    }
   ],
   "source": [
    "async for step in app.astream(\n",
    "    {'contents': [doc.page_content for doc in split_docs]}\n",
    "):\n",
    "    print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cf695f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
