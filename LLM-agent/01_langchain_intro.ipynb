{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841639fb",
   "metadata": {},
   "source": [
    "# Langchain Intro\n",
    "\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603e5f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb3f9926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 11, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArZwVIeTYIgBBHnCOWqJCncYCvaC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c027e0d3-7739-41a1-bfe4-7cb4095c67b3-0', usage_metadata={'input_tokens': 11, 'output_tokens': 9, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a1489a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'안녕하세요.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면, 한국어로 번역을 해주는 AI를 만들고 싶다면?\n",
    "\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3963b770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Essere pieno', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 34, 'total_tokens': 38, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqKGBiOWbzFtZP3rYYsnmZKbgCQC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--671e088f-1edc-466d-9641-74a6c7fcc7c6-0', usage_metadata={'input_tokens': 34, 'output_tokens': 4, 'total_tokens': 38, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    {'role': 'system', 'content': '한국어를 이탈리어로 번역해줘'},\n",
    "    {'role': 'user', 'content': '배부르다'},\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d13fe7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "|S|ono| pien|o|/a|.||"
     ]
    }
   ],
   "source": [
    "print(type(llm))\n",
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c092bf8",
   "metadata": {},
   "source": [
    "# Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법\n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서 (chaining)하여 한번에 실행(invoke)할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법 (LCEL-LanChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb43ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司が食べたいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 30, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqecp7Db8SgU0ZbOaP7FKNgdpq9t', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--360df174-e097-4a9f-828a-e8166f2e3bf4-0', usage_metadata={'input_tokens': 30, 'output_tokens': 12, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채팅을 할 경우에는 ChatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59ff9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 27, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CAqfNcclb1QIsdqKfXZsE2Lo30UxT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9e8f9922-8a60-429e-afbb-4ab3dd23728d-0', usage_metadata={'input_tokens': 27, 'output_tokens': 7, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780ff8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to eat kimchi stew.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | llm | output_parser\n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌개가 먹고싶다'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fa1175f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025년 전반기 매출 분석을 위한 단계별 데이터 분석 절차는 다음과 같이 나눌 수 있습니다:\n",
      "\n",
      "1. **데이터 수집 및 확보**\n",
      "   - 2025년 1월부터 6월까지의 매출 데이터 확보\n",
      "   - 관련 부서 또는 시스템에서 데이터 추출 (ERP, POS 시스템 등)\n",
      "   - 데이터의 형식(Excel, CSV, 데이터베이스 등)을 확인하고 수집\n",
      "\n",
      "2. **데이터 전처리**\n",
      "   - 결측값 및 이상치 처리\n",
      "   - 날짜 포맷 통일 및 기간 필터링 (2025년 1~6월 데이터만 선택)\n",
      "   - 매출 금액, 제품명, 카테고리, 고객 정보 등 필요한 변수 정리\n",
      "   - 데이터 정제 및 통합(여러 소스가 있다면 병합)\n",
      "\n",
      "3. **기초 통계 및 탐색적 데이터 분석 (EDA)**\n",
      "   - 전체 매출액, 건수, 평균값 등 기초 통계 확인\n",
      "   - 월별/분기별 매출 추이 분석\n",
      "   - 제품별, 카테고리별, 지역별 매출 분포 파악\n",
      "   - 고객 세그먼트별 매출 분석\n",
      "   - 시간대별/일별 트렌드 탐색\n",
      "\n",
      "4. **시각화 및 패턴 분석**\n",
      "   - 시계열 그래프를 통한 월별/주별 매출 추이 시각화\n",
      "   - 히트맵 또는 파이차트로 제품 또는 지역별 기여도 분석\n",
      "   - 이상치 또는 특별한 패턴 탐색\n",
      "\n",
      "5. **추세 및 인사이트 도출**\n",
      "   - 성장 또는 하락하는 트렌드 파악\n",
      "   - 성수기 또는 비수기 구간 식별\n",
      "   - 중요한 영향 변수 또는 요인 분석\n",
      "\n",
      "6. **보고서 및 인사이트 전달**\n",
      "   - 분석 결과 요약\n",
      "   - 주요 인사이트 및 시사점 정리\n",
      "   - 향후 개선 방안 또는 추가 분석 필요성 제안\n",
      "\n",
      "이 단계별 과정을 따라가면 2025년 전반기 매출 현황을 체계적으로 파악하고, 의미 있는 인사이트를 도출할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행 PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가입니다.\n",
    "사용자의 질문을 EDA에 활용할 수 있도록 단계를 나눠주세요.\n",
    "\n",
    "질문: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c870453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^202^5^년^ 전^반^기^ 매^출^ 분석^을^ 위한^ 데이터^ 분석^ 단계^는^ 다음^과^ 같이^ 나^눌^ 수^ 있습니다^:\n",
      "\n",
      "^1^.^ 데이터^ 수^집^  \n",
      "^  ^ -^ ^202^5^년^ ^1^월^~^6^월^ 매^출^ 데이터^ 수^집^  \n",
      "^  ^ -^ 관련^ 부^서^ 또는^ 시스템^에서^ 데이터^ 확보^ (^예^:^ POS^ 시스템^,^ ERP^ 등^)^  \n",
      "^  ^ -^ 매^출^ 데이터^뿐^만^ 아니라^ 관련^된^ 부^가^ 데이터^(^제품^,^ 고객^,^ 영^업^ 채^널^ 등^)^도^ 함께^ 수^집^ 가능^\n",
      "\n",
      "^2^.^ 데이터^ 검^증^ 및^ 정^제^  \n",
      "^  ^ -^ 데이터^ 무^결^성^ 확인^ (^중^복^,^ 결^측^치^,^ 이상^치^ 여부^ 확인^)^  \n",
      "^  ^ -^ 데이터^ 포^맷^ 통^일^ (^날^짜^ 형^식^,^ 단^위^ 등^)^  \n",
      "^  ^ -^ 필요^ 없는^ 데이터^ 제거^ 및^ 필^터^링^\n",
      "\n",
      "^3^.^ 기^초^ 통^계^ 분석^(^기^술^ 통^계^)^  \n",
      "^  ^ -^ 전체^ 매^출^ 총^액^,^ 평균^,^ 중앙^값^ 등^ 기^초^ 통^계^ 계산^  \n",
      "^  ^ -^ 월^별^,^ 제품^별^,^ 고객^별^ 매^출^ 분^포^ 파^악^  \n",
      "^  ^ -^ 트^렌^드^ 및^ 계^절^성^ 파^악^ 위한^ 시^계^열^ 그래^프^ 생성^\n",
      "\n",
      "^4^.^ 데이터^ 탐^색^적^ 분석^(^EDA^)^  \n",
      "^  ^ -^ 시^계^열^ 분석^을^ 통해^ 매^출^ 패^턴^ 및^ 트^렌^드^ 이해^  \n",
      "^  ^ -^ 이상^치^ 및^ 특^이^점^ 발견^  \n",
      "^  ^ -^ 상^관^관^계^ 분석^ (^예^:^ 프로^모^션^과^ 매^출^의^ 연^관^성^)^  \n",
      "^  ^ -^ 하^위^ 그룹^별^(^제품^군^,^ 고객^군^,^ 영^업^ 채^널^ 등^)^ 매^출^ 분석^\n",
      "\n",
      "^5^.^ 인^사이트^ 도^출^ 및^ 시^각^화^  \n",
      "^  ^ -^ 주요^ 매^출^ 증^감^ 원^인^ 분석^  \n",
      "^  ^ -^ 매^출^ 급^증^/^감^소^ 시^점^과^ 이벤트^(^프로^모^션^,^ 시장^ 변화^ 등^)^ 연결^  \n",
      "^  ^ -^ 분석^ 결과^를^ 시^각^적^ 보고^서^,^ 차^트^,^ 대^시^보^드^로^ 정^리^\n",
      "\n",
      "^6^.^ 결^론^ 및^ 전략^적^ 제^언^  \n",
      "^  ^ -^ 데이터^ 기반^으로^ 향^후^ 판매^ 전략^ 제^언^  \n",
      "^  ^ -^ 개선^이^ 필요한^ 영역^ 제^시^ (^예^:^ 특정^ 제품^ 또는^ 채^널^의^ 부^진^)^  \n",
      "^  ^ -^ 지속^적인^ 모^니^터^링^ 방^안^ 설^계^\n",
      "\n",
      "^이^ 단^계를^ 참고^하여^ 관련^ 데이터를^ 준비^하고^ 분석^을^ 진행^하면^,^ ^202^5^년^ 전^반^기^ 매^출^에^ 대한^ 심^도^ 있는^ 인^사이트^를^ 얻^으^실^ 수^ 있습니다^.^^"
     ]
    }
   ],
   "source": [
    "# chain 은 Runnable 객체이기 때문에 invoke, stream, batch 메서드 사용가능\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='^', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9873c8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Langchain은 자연어 처리 및 생성 분야에서 활용되는 프레임워크로, 다양한 언어모델과 도구들을 쉽게 연결하고 사용할 수 있도록 도와줍니다. 이를 통해 사용자는 복잡한 자연어 애플리케이션을 빠르게 개발하고, 여러 기능을 통합할 수 있습니다. 또한, 데이터 소스와의 연동, 체인 구성, 사용자 정의 로직 등을 지원하여 확장성과 유연성을 제공합니다.',\n",
       " 'Langsmith는 OpenAI에서 개발한 대화형 인공지능 플랫폼으로, 사용자와 자연스럽게 상호작용할 수 있도록 설계되었습니다. 이 플랫폼은 사용자 맞춤형 챗봇 및 AI 애플리케이션을 쉽게 구축하고 배포할 수 있는 도구를 제공합니다. 또한, 개발자들이 보다 효율적으로 AI 모델을 활용하여 다양한 분야에 활용할 수 있도록 지원합니다.',\n",
       " 'LangGraph는 자연어 처리와 그래프 이론을 결합한 기술로, 언어 데이터를 그래프로 표현하여 의미 관계를 파악하는 방법입니다. 이를 통해 문장 내 단어들 간의 연결성과 의미적 유사성을 효과적으로 분석할 수 있습니다. LangGraph는 특히 텍스트 이해, 정보 추출, 그리고 질의응답 시스템 등 다양한 자연어 처리 응용 분야에서 활용됩니다.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}에 대해서 3문장으로 설명해줘')\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.batch([\n",
    "    {'topic': 'Langchain'},\n",
    "    {'topic': 'Langsmith'},\n",
    "    {'topic': 'Langgraph'}\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
